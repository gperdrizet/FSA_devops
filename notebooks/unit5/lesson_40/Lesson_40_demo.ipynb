{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b61aad",
   "metadata": {},
   "source": [
    "# Lesson 40: Distributed representations demonstration\n",
    "\n",
    "This notebook demonstrates using pre-trained word embeddings and extending them to document-level representations.\n",
    "\n",
    "**1. Pre-trained word embeddings**\n",
    "- 1.1. Loading pre-trained Word2Vec\n",
    "- 1.2. Word similarity and analogies\n",
    "\n",
    "**2. Document embeddings**\n",
    "- 2.1. Averaging word vectors\n",
    "- 2.2. Doc2Vec\n",
    "\n",
    "**3. Document similarity comparison**\n",
    "\n",
    "\n",
    "## Notebook set up\n",
    "\n",
    "**Note**: depending on your environment, you may need to install NLTK and gensim:\n",
    "\n",
    "```text\n",
    "pip install nltk gensim\n",
    "```\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec35574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gensim.downloader as api\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c1f45b",
   "metadata": {},
   "source": [
    "### Sample documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0605a20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample documents:\n",
      "  Doc 1: The king ruled his kingdom with wisdom and justice\n",
      "  Doc 2: The queen governed her realm with grace and power\n",
      "  Doc 3: Machine learning algorithms can learn patterns from data\n",
      "  Doc 4: Deep neural networks are powerful for pattern recognition\n",
      "  Doc 5: The cat sat lazily on the warm sunny windowsill\n",
      "  Doc 6: Dogs love playing fetch in the park with their owners\n"
     ]
    }
   ],
   "source": [
    "# Sample documents for demonstration\n",
    "documents = [\n",
    "    'The king ruled his kingdom with wisdom and justice',\n",
    "    'The queen governed her realm with grace and power',\n",
    "    'Machine learning algorithms can learn patterns from data',\n",
    "    'Deep neural networks are powerful for pattern recognition',\n",
    "    'The cat sat lazily on the warm sunny windowsill',\n",
    "    'Dogs love playing fetch in the park with their owners'\n",
    "]\n",
    "\n",
    "# Tokenize documents\n",
    "tokenized_docs = [word_tokenize(doc.lower()) for doc in documents]\n",
    "\n",
    "print('Sample documents:')\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f'  Doc {i+1}: {doc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3cd8e2",
   "metadata": {},
   "source": [
    "## 1. Pre-trained word embeddings\n",
    "\n",
    "### 1.1. Loading pre-trained Word2Vec\n",
    "\n",
    "Pre-trained embeddings capture semantic relationships learned from large text corpora.\n",
    "\n",
    "Gensim [downloader](https://radimrehurek.com/gensim/downloader.html) documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb216cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
      "Vocabulary size: 400000\n",
      "Vector dimensions: 100\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained GloVe embeddings (smaller than Google News for demo)\n",
    "# Using glove-wiki-gigaword-100 (100-dimensional vectors)\n",
    "w2v_model = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "print(f'Vocabulary size: {len(w2v_model)}')\n",
    "print(f'Vector dimensions: {w2v_model.vector_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4fe67",
   "metadata": {},
   "source": [
    "### 1.2. Word similarity and analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a47d14f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most similar to \"king\":\n",
      "  prince: 0.768\n",
      "  queen: 0.751\n",
      "  son: 0.702\n",
      "  brother: 0.699\n",
      "  monarch: 0.698\n",
      "\n",
      "Words most similar to \"computer\":\n",
      "  computers: 0.875\n",
      "  software: 0.837\n",
      "  technology: 0.764\n",
      "  pc: 0.737\n",
      "  hardware: 0.729\n"
     ]
    }
   ],
   "source": [
    "# Find similar words\n",
    "print('Words most similar to \"king\":')\n",
    "for word, score in w2v_model.most_similar('king', topn=5):\n",
    "    print(f'  {word}: {score:.3f}')\n",
    "\n",
    "print('\\nWords most similar to \"computer\":')\n",
    "for word, score in w2v_model.most_similar('computer', topn=5):\n",
    "    print(f'  {word}: {score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0beafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy: king - man + woman = ?\n",
      "  queen: 0.770\n",
      "  monarch: 0.684\n",
      "  throne: 0.676\n",
      "\n",
      "Analogy: paris - france + germany = ?\n",
      "  berlin: 0.885\n",
      "  frankfurt: 0.799\n",
      "  vienna: 0.768\n"
     ]
    }
   ],
   "source": [
    "# Word analogies: king - man + woman = ?\n",
    "print('Analogy: king - man + woman = ?')\n",
    "result = w2v_model.most_similar(positive=['king', 'woman'], negative=['man'], topn=3)\n",
    "\n",
    "for word, score in result:\n",
    "    print(f'  {word}: {score:.3f}')\n",
    "\n",
    "print('\\nAnalogy: paris - france + germany = ?')\n",
    "result = w2v_model.most_similar(positive=['paris', 'germany'], negative=['france'], topn=3)\n",
    "\n",
    "for word, score in result:\n",
    "    print(f'  {word}: {score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38d4670",
   "metadata": {},
   "source": [
    "## 2. Document embeddings\n",
    "\n",
    "### 2.1. Averaging word vectors\n",
    "\n",
    "A simple approach to create document embeddings is to average the word vectors of all words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041d40b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document vectors shape: (6, 100)\n"
     ]
    }
   ],
   "source": [
    "# Create document vector by averaging word vectors\n",
    "def get_doc_vector_avg(tokens, model):\n",
    "\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in model:\n",
    "            vectors.append(model[token])\n",
    "\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    return np.zeros(model.vector_size)\n",
    "\n",
    "# Create document vectors\n",
    "doc_vectors_avg = np.array([get_doc_vector_avg(doc, w2v_model) for doc in tokenized_docs])\n",
    "\n",
    "print(f'Document vectors shape: {doc_vectors_avg.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d57cb08",
   "metadata": {},
   "source": [
    "### 2.2. Doc2Vec\n",
    "\n",
    "Doc2Vec learns document embeddings directly, treating each document as a unique entity during training.\n",
    "\n",
    "Gensim [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html) documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44caf250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec vectors shape: (6, 100)\n"
     ]
    }
   ],
   "source": [
    "# Prepare tagged documents for Doc2Vec\n",
    "tagged_docs = [TaggedDocument(words=doc, tags=[str(i)]) for i, doc in enumerate(tokenized_docs)]\n",
    "\n",
    "# Train Doc2Vec model\n",
    "doc2vec_model = Doc2Vec(\n",
    "    documents=tagged_docs,\n",
    "    vector_size=100,\n",
    "    window=2,\n",
    "    min_count=1,\n",
    "    epochs=100,\n",
    "    seed=315\n",
    ")\n",
    "\n",
    "# Get document vectors\n",
    "doc_vectors_d2v = np.array([doc2vec_model.dv[str(i)] for i in range(len(documents))])\n",
    "\n",
    "print(f'Doc2Vec vectors shape: {doc_vectors_d2v.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e2b31",
   "metadata": {},
   "source": [
    "## 3. Document similarity comparison\n",
    "\n",
    "Compare how averaging and Doc2Vec capture document similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0457aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document similarity (Averaging method):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc 1</th>\n",
       "      <th>Doc 2</th>\n",
       "      <th>Doc 3</th>\n",
       "      <th>Doc 4</th>\n",
       "      <th>Doc 5</th>\n",
       "      <th>Doc 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc 1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 2</th>\n",
       "      <td>0.933</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 3</th>\n",
       "      <td>0.632</td>\n",
       "      <td>0.670</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 4</th>\n",
       "      <td>0.754</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.844</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 5</th>\n",
       "      <td>0.701</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.630</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 6</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.820</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Doc 1  Doc 2  Doc 3  Doc 4  Doc 5  Doc 6\n",
       "Doc 1  1.000  0.933  0.632  0.754  0.701  0.832\n",
       "Doc 2  0.933  1.000  0.670  0.774  0.747  0.867\n",
       "Doc 3  0.632  0.670  1.000  0.844  0.580  0.731\n",
       "Doc 4  0.754  0.774  0.844  1.000  0.630  0.772\n",
       "Doc 5  0.701  0.747  0.580  0.630  1.000  0.820\n",
       "Doc 6  0.832  0.867  0.731  0.772  0.820  1.000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarity matrices\n",
    "sim_matrix_avg = cosine_similarity(doc_vectors_avg)\n",
    "sim_matrix_d2v = cosine_similarity(doc_vectors_d2v)\n",
    "\n",
    "# Create dataframes with document labels\n",
    "doc_labels = [f'Doc {i+1}' for i in range(len(documents))]\n",
    "\n",
    "sim_avg_df = pd.DataFrame(sim_matrix_avg.round(3), index=doc_labels, columns=doc_labels)\n",
    "sim_d2v_df = pd.DataFrame(sim_matrix_d2v.round(3), index=doc_labels, columns=doc_labels)\n",
    "\n",
    "print('Document similarity (Averaging method):')\n",
    "sim_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "421bb6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document similarity (Doc2Vec method):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc 1</th>\n",
       "      <th>Doc 2</th>\n",
       "      <th>Doc 3</th>\n",
       "      <th>Doc 4</th>\n",
       "      <th>Doc 5</th>\n",
       "      <th>Doc 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc 1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 2</th>\n",
       "      <td>0.290</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 3</th>\n",
       "      <td>0.356</td>\n",
       "      <td>0.364</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 4</th>\n",
       "      <td>0.252</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.433</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 5</th>\n",
       "      <td>0.274</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.339</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 6</th>\n",
       "      <td>0.286</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.249</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Doc 1  Doc 2  Doc 3  Doc 4  Doc 5  Doc 6\n",
       "Doc 1  1.000  0.290  0.356  0.252  0.274  0.286\n",
       "Doc 2  0.290  1.000  0.364  0.250  0.360  0.287\n",
       "Doc 3  0.356  0.364  1.000  0.433  0.324  0.336\n",
       "Doc 4  0.252  0.250  0.433  1.000  0.339  0.362\n",
       "Doc 5  0.274  0.360  0.324  0.339  1.000  0.249\n",
       "Doc 6  0.286  0.287  0.336  0.362  0.249  1.000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Document similarity (Doc2Vec method):')\n",
    "sim_d2v_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2040442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected similar pairs:\n",
      "  - Doc 1 & Doc 2 (both about royalty/governance)\n",
      "  - Doc 3 & Doc 4 (both about machine learning)\n",
      "  - Doc 5 & Doc 6 (both about pets/animals)\n",
      "\n",
      "Actual most similar pairs (averaging):\n",
      "  Doc 1 most similar to: Doc 2\n",
      "  Doc 3 most similar to: Doc 4\n",
      "  Doc 5 most similar to: Doc 6\n"
     ]
    }
   ],
   "source": [
    "# Find most similar document pairs\n",
    "print('Expected similar pairs:')\n",
    "print('  - Doc 1 & Doc 2 (both about royalty/governance)')\n",
    "print('  - Doc 3 & Doc 4 (both about machine learning)')\n",
    "print('  - Doc 5 & Doc 6 (both about pets/animals)')\n",
    "\n",
    "print('\\nActual most similar pairs (averaging):')\n",
    "print(f'  Doc 1 most similar to: Doc {np.argsort(sim_matrix_avg[0])[-2] + 1}')\n",
    "print(f'  Doc 3 most similar to: Doc {np.argsort(sim_matrix_avg[2])[-2] + 1}')\n",
    "print(f'  Doc 5 most similar to: Doc {np.argsort(sim_matrix_avg[4])[-2] + 1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
