{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "457956e0",
   "metadata": {},
   "source": [
    "# Lesson 28: TensorFlow/Keras neural network demonstration\n",
    "\n",
    "## Notebook set up\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5271c9d",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "### 1.1. Load occupancy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_df = pd.read_csv('occupancy_data.csv')\n",
    "occupancy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388df321",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42232b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Occupancy'\n",
    "features = ['Temperature','Humidity','Light','CO2','HumidityRatio']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae08764",
   "metadata": {},
   "source": [
    "### 1.2. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the data into training and testing sets\n",
    "# Use train_test_split with random_state=315"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d04ed",
   "metadata": {},
   "source": [
    "### 1.3. Standard scale\n",
    "\n",
    "#### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a StandardScaler and fit it on the training features\n",
    "# Then transform both training and testing features\n",
    "# Hint: Fit only on training data to avoid data leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2346c36",
   "metadata": {},
   "source": [
    "## 2. Logistic regression baseline\n",
    "\n",
    "### 2.1. Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2635d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and fit a LogisticRegression model\n",
    "# Use n_jobs=-1 and random_state=315"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b30c63",
   "metadata": {},
   "source": [
    "### 2.2. Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f41ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make predictions on the test set and calculate accuracy\n",
    "# Print the accuracy formatted to 4 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbd84c",
   "metadata": {},
   "source": [
    "## 3. Keras Sequential API model\n",
    "\n",
    "The Sequential API is the simplest way to build a neural network in Keras. It allows you to create models layer-by-layer in a linear stack.\n",
    "\n",
    "### 3.1. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0511fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set the random seed for reproducibility\n",
    "# tf.random.set_seed(315)\n",
    "\n",
    "# TODO: Create a Sequential model with:\n",
    "# - Input layer with shape (5,) for 5 features\n",
    "# - Dense layer with 64 units and 'relu' activation\n",
    "# - Dense layer with 32 units and 'relu' activation  \n",
    "# - Dense output layer with 1 unit and 'sigmoid' activation (for binary classification)\n",
    "\n",
    "# TODO: Compile the model with:\n",
    "# - Adam optimizer with learning_rate=0.001\n",
    "# - 'binary_crossentropy' loss function\n",
    "# - 'accuracy' metric\n",
    "\n",
    "# TODO: Display the model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edbedf4",
   "metadata": {},
   "source": [
    "### 3.2. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the model using .fit() with:\n",
    "# - Training features and labels\n",
    "# - epochs=75\n",
    "# - batch_size=64\n",
    "# - validation_split=0.2\n",
    "# - verbose=1\n",
    "\n",
    "# TODO: Print the final training and validation loss and accuracy\n",
    "# Access the history using: history.history['loss'], history.history['val_loss'], etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e855aa43",
   "metadata": {},
   "source": [
    "### 3.3. Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79038e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the learning curves (loss and accuracy over epochs)\n",
    "# Create a figure with 2 subplots side by side\n",
    "# Left plot: training and validation loss\n",
    "# Right plot: training and validation accuracy\n",
    "# Include proper titles, labels, and legends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9edb80f",
   "metadata": {},
   "source": [
    "### 3.4. Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get predictions from the Sequential model on the test set\n",
    "# - Use .predict() to get probabilities\n",
    "# - Convert probabilities to class predictions using threshold of 0.5\n",
    "# - Calculate and print the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36bf90d",
   "metadata": {},
   "source": [
    "### 3.5. Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d06622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a confusion matrix visualization\n",
    "# Use ConfusionMatrixDisplay.from_predictions()\n",
    "# Include the accuracy in the title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a53d68",
   "metadata": {},
   "source": [
    "## 4. Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f7c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the accuracy of both models for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create side-by-side confusion matrix comparison\n",
    "# Create a figure with 2 subplots\n",
    "# Left: Logistic regression confusion matrix\n",
    "# Right: Sequential API model confusion matrix\n",
    "# Include accuracy in the titles"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
